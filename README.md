# Challengeâ€¯1a PDF Processor

A lightweight, containerized Python pipeline that scans a folder of PDF files, extracts document title and hierarchical outline (headings), and emits JSON conforming to the official `output_schema.json`. Designed for CPUâ€‘only execution (no internet), â‰¤â€¯10â€¯s per 50â€‘page PDF on 8â€¯vCPUs, <â€¯200â€¯MB install size.

---

## ðŸ“ Repository Layout

```text
Challenge_1a/
â”œâ”€â”€ sample_dataset/
â”‚   â”œâ”€â”€ pdfs/                 # â† place your input PDFs here
â”‚   â”œâ”€â”€ outputs/              # â† JSON outputs will be written here
â”‚   â””â”€â”€ schema/
â”‚       â””â”€â”€ output_schema.json  # official JSON Schema (draftâ€‘04)
â”œâ”€â”€ Dockerfile                # Docker build / runtime configuration
â”œâ”€â”€ process_pdfs.py           # Main processing script
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This documentation
```

---

## ðŸš€ Solution Overview

1. **Metadata & Title Extraction**  
   - Reads `Title` from PDF metadata (if present).  
   - If empty, scans pageâ€¯1 for the largestâ€‘font text span as the inferred title.

2. **Text Block Segmentation**  
   - Uses **PyMuPDF (fitz)** to streamâ€‘read each page.  
   - Splits content into â€œblocksâ€ of contiguous text, computing a weighted mean font size per block.

3. **Outline Detection**  
   - Computes the documentâ€™s meanâ€¯(Î¼) and populationâ€¯stdâ€¯(Ïƒ) of block font sizes.  
   - Marks any block with fontâ€‘size â‰¥â€¯Î¼â€¯+â€¯0.5Â·Ïƒ as a heading candidate.  
   - Ranks distinct heading sizes descending â†’ maps largestâ†’`H1`, nextâ†’`H2`, etc.  
   - Emits an `"outline"` array in natural page/block order.

4. **JSON Assembly & Validation**  
   - Builds a Python dict with exactly two topâ€‘level keys:  
     - `"title"`: _string_  
     - `"outline"`: _array_ of `{ level: "Hn", text: "...", page: int }`  
   - Validates against the provided **draftâ€‘04 JSONâ€‘Schema** using **jsonschema**.

5. **Parallel Processing**  
   - Uses `concurrent.futures.ProcessPoolExecutor` with 8 workers.  
   - Ensures each PDF is processed in its own Python process (avoids GIL).

---

## ðŸ§© Libraries & Tools

- **[PyMuPDF (fitz)](https://pymupdf.readthedocs.io/)** (v1.25.1)  
  Ultraâ€‘fast PDF parser for text, fonts, and layout.  
- **[jsonschema](https://python-jsonschema.readthedocs.io/)** (v4.22.0)  
  Draftâ€‘04 validator for enforcing JSON output format.  
- **Pythonâ€¯3.10+** (tested on 3.10)  
- **Docker** for reproducible, networkâ€‘restricted execution.

_No machineâ€‘learning models are used â€” all â€œintelligenceâ€ is simple fontâ€‘size heuristics._

---

## ðŸ Local Installation & Usage

1. **Clone the repo** and navigate into it:
   ```bash
   git clone https://github.com/samruddhikurhe/Adobe_hackthon_project_1a.git
   cd Challenge_1a
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Place your PDFs** in:
   ```
   sample_dataset/pdfs/
   ```

4. **Run the processor**:
   ```bash
   python process_pdfs.py
   ```

5. **Inspect JSON outputs**:
   ```bash
   sample_dataset/outputs/*.json
   ```

6. **Validate outputs**:
   ```bash
   python - <<'PYCODE'
   import json, glob
   from jsonschema import validate
   schema = json.load(open("sample_dataset/schema/output_schema.json"))
   for f in glob.glob("sample_dataset/outputs/*.json"):
       validate(json.load(open(f)), schema)
       print(f"{f} âœ…")
   PYCODE
   ```

---

## ðŸ³ Docker Usage

1. **Build the image** (amd64):
   ```bash
   docker build --platform linux/amd64 -t pdf-processor .
   ```

2. **Run with mounted folders**:
   ```bash
   docker run --rm -v "$(pwd)/sample_dataset/pdfs:/app/sample_dataset/pdfs:ro" -v "$(pwd)/sample_dataset/outputs:/app/sample_dataset/outputs" --network none pdf-processor
   ```

3. **Check outputs** on host:
   ```bash
   ls sample_dataset/outputs/*.json
   ```

---

## ðŸ“Š Performance & Constraints

- **Execution time**: ~0.08â€¯s per 1â€‘page PDF; ~8â€¯s for a 50â€‘page document on 8â€¯vCPUs.  
- **Memory**: <â€¯200â€¯MB total for all dependencies.  
- **Network**: Completely offline at runtime (`--network none`).  
- **CPU**: Scales to 8 workers; easily adjustable in `process_pdfs.py`.

---

